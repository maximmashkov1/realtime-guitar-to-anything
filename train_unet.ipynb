{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f49b75b-4c04-44f7-baa4-556d4b08b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import GuitarToneCloning\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c305cf3-c096-4b34-83ea-91e0e8db9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GuitarToneCloning().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab4c8f-e24b-4425-b8ee-a2ecebf81daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import sys\n",
    "import types\n",
    "\n",
    "\n",
    "model = torch.load('backup_20k',weights_only=False)\n",
    "model_k0 = torch.load('flow_k0',weights_only=False).eval()\n",
    "\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770abd8-780b-40ec-8f40-cb4f4dbf3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim import Optimizer, AdamW\n",
    "import math\n",
    "\n",
    "class LinearWarmupCosineAnnealingLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, total_steps, decay_factor=0.1, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.decay_factor = decay_factor\n",
    "\n",
    "        self.base_lrs = [group['lr'] for group in optimizer.param_groups]\n",
    "        self.min_lrs = [base_lr * decay_factor for base_lr in self.base_lrs]\n",
    "\n",
    "        super(LinearWarmupCosineAnnealingLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            return [\n",
    "                base_lr * self.last_epoch / self.warmup_steps\n",
    "                for base_lr in self.base_lrs\n",
    "            ]\n",
    "        else:\n",
    "            progress = (self.last_epoch - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
    "            progress = min(max(progress, 0.0), 1.0)\n",
    "            return [\n",
    "                min_lr + (base_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "                for base_lr, min_lr in zip(self.base_lrs, self.min_lrs)\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010f210-37aa-4301-9c2b-18e3908a164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_decay = ['bias', 'norm'] \n",
    "params = list(model.named_parameters())\n",
    "for param in model.vocoder.parameters():\n",
    "    param.requires_grad_(False)\n",
    "for param in model.vocoder_disc.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "lr = 2e-4\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "  \n",
    "        'params': [p for n, p in params if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.001,\n",
    "        'lr': lr\n",
    "        },\n",
    "        {\n",
    "        'params': [p for n, p in params if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "        'lr': lr\n",
    "        },\n",
    "]\n",
    "optimizer = AdamW(params=optimizer_grouped_parameters)\n",
    "scheduler = LinearWarmupCosineAnnealingLR(optimizer=optimizer, warmup_steps=2000, total_steps=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c00500-88a6-4e36-9dd3-0f5f4a1fbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import os\n",
    "from utils import mel_spectrogram\n",
    "sr=24000\n",
    "frame_size=256\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "def augment_waveform(waveform, sample_rate, time_stretches, pitch_shifts):\n",
    "\n",
    "    if waveform.dim() == 2 and waveform.size(0) > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "    silence = torch.zeros((int(0.5 * sample_rate)))\n",
    "    results = []\n",
    "\n",
    "    for ts, ps in product(time_stretches, pitch_shifts):\n",
    "        augmented = waveform.clone()\n",
    "        if ts != 1.0:\n",
    "            new_sr = int(sample_rate * ts)\n",
    "            resample = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sr)\n",
    "            augmented = resample(augmented)\n",
    "\n",
    "        if ps != 0:\n",
    "            pitch_shift = torchaudio.transforms.PitchShift(sample_rate=sample_rate, n_steps=ps)\n",
    "            augmented = pitch_shift(augmented)\n",
    "        results.append(augmented.detach())\n",
    "        results.append(silence.detach())\n",
    "    return torch.cat(results[:-1])\n",
    "\n",
    "\n",
    "\n",
    "y_path=\"violin.wav\"\n",
    "x_path=\"clean_guitar.wav\"\n",
    "\n",
    "\n",
    "y=torchaudio.load(y_path)\n",
    "y=torchaudio.functional.resample(y[0], y[1], sr)[0]\n",
    "\n",
    "x=torchaudio.load(x_path)\n",
    "x=torchaudio.functional.resample(x[0], x[1], sr)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f4ebf-45d5-4d76-bbae-8ebe78029dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "y = augment_waveform(y,sr, [1.1, 1.0, 0.9], [-2,-1,0,1,2])\n",
    "import pickle\n",
    "with open('cached_augmented.pkl','wb') as f:\n",
    "    pickle.dump(y,f)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142184a-7f49-4026-8cc7-3565688e697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cached_augmented.pkl','rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f4f18-2236-4ff2-a9a1-6a1e8d5b3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_y = mel_spectrogram(y.unsqueeze(0)).squeeze(0).T\n",
    "mel_x = mel_spectrogram(x.unsqueeze(0)).squeeze(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c510e15-ebaa-4d68-90a8-6b8892708243",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.norm_params['mean'], model.norm_params['std'] = mel_y.mean().item(), mel_y.std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e079d-bfd6-44d6-878c-2e871aa12d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import copy\n",
    "\n",
    "plt.ion() \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "flow = []\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d198b46-a116-4e3b-95c4-afcec3d00b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint\n",
    "rf=32\n",
    "model.flow.last_h=None\n",
    "model=model.cuda()\n",
    "def train_unet(d1, raw_mels, optimizer):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    raw_mels = model.mel_normalize(raw_mels)\n",
    "    d1 = model.mel_normalize(d1)\n",
    "    ########################\n",
    "    #Train f_0\n",
    "    ########################\n",
    "    \"\"\"\n",
    "    t = torch.rand(raw_mels.shape[0],1,1, device=raw_mels.device)\n",
    "    \n",
    "    noise = torch.randn_like(raw_mels)\n",
    "    noised_mels = t*raw_mels + (1-t)*noise\n",
    "\n",
    "    \n",
    "    v_pred = model.flow(noised_mels, t)\n",
    "    v_target = raw_mels-noise\n",
    "    \"\"\"\n",
    "    ########################\n",
    "    #Rectify\n",
    "    ########################\n",
    "    coeff = 0.3\n",
    "    steps = 30\n",
    "    noise = torch.randn_like(raw_mels)\n",
    "    noised_mels = coeff*raw_mels + (1-coeff)*noise\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_k0.flow.last_h = None\n",
    "        \n",
    "        @torch.inference_mode()\n",
    "        def ode_func(t, x):\n",
    "            print(t)\n",
    "            t_batch = torch.ones(x.shape[0], 1, 1, device=x.device) * t\n",
    "            return model_k0.flow(x, t_batch)\n",
    "        \n",
    "        t_span = torch.linspace(coeff, 1.0, steps=int(steps*(1-coeff))).to(raw_mels.device)\n",
    "        \n",
    "        trajectories = odeint(\n",
    "            ode_func, \n",
    "            noised_mels.detach(), \n",
    "            t_span, \n",
    "            method='euler',\n",
    "            options={'step_size': 1/steps}\n",
    "        )\n",
    "        z_refined = trajectories[-1]\n",
    "        v_target = (z_refined - noise)\n",
    "    ########################\n",
    "    ########################\n",
    "    #plt.matshow((noise[0][...,rf:]+v_target[0][...,rf:]).cpu().detach().numpy(),cmap='viridis')\n",
    "    #plt.show()\n",
    "    #input()\n",
    "    \n",
    "    t = torch.rand(raw_mels.shape[0],1,1, device=raw_mels.device)\n",
    "    noised_mels = t*z_refined + (1-t)*noise\n",
    "    v_pred = model.flow(noised_mels, t)\n",
    "    loss_div = F.mse_loss(v_pred[...,rf:], v_target[...,rf:])\n",
    "\n",
    "    print(v_pred[...,rf:].std().item())\n",
    "    mean = F.interpolate(raw_mels.transpose(-1,-2), (10))\n",
    "    restored_mean = model.mean_restoration(mean)\n",
    "    loss_rest = F.mse_loss(restored_mean,mean)\n",
    "    print('rest',loss_rest.item())\n",
    "    \n",
    "    (loss_div+loss_rest).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_div.item()\n",
    "import random\n",
    "import numpy as np\n",
    "N=32\n",
    "model.train()\n",
    "while True:\n",
    "    i+=1\n",
    "    training_window = 384\n",
    "    max_x = mel_x.shape[0]-training_window\n",
    "    max_y = mel_y.shape[0]-training_window\n",
    "    \n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    \n",
    "    for _ in range(N):\n",
    "        x_idx = random.randint(0, max_x)\n",
    "        y_idx = random.randint(0, max_y)\n",
    "        \n",
    "        x_train = mel_x[x_idx:x_idx + training_window].clone().T.cuda().unsqueeze(0)\n",
    "        y_train = mel_y[y_idx:y_idx + training_window].clone().T.cuda().unsqueeze(0)\n",
    "\n",
    "        x_batch.append(x_train)\n",
    "        y_batch.append(y_train)\n",
    "    \n",
    "    x_batch = torch.cat(x_batch, dim=0)\n",
    "    y_batch = torch.cat(y_batch, dim=0)\n",
    "    loss_flow = train_unet(x_batch,y_batch,optimizer)\n",
    "    scheduler.step()\n",
    "    flow.append(loss_flow)\n",
    "\n",
    "    \n",
    "    if i%10==0:\n",
    "        clear_output(wait=True) \n",
    "        ax.clear()\n",
    "        ax.plot(np.array(flow), label='flow')\n",
    "        ax.legend()\n",
    "        display(fig)\n",
    "        torch.cuda.empty_cache()\n",
    "    if i %1000 ==0:\n",
    "        torch.save(model,'flow_k1_ckpt')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5acc47-2e45-4106-86bd-ff43a405e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "window=32768*10\n",
    "start=0#33607040#602352#33607040\n",
    "mel_orig = mel_x[start//256:(start+window)//256].clone().cuda().unsqueeze(0)\n",
    "\n",
    "mel_ = model.mel_normalize(mel_orig)\n",
    "mean = F.interpolate(mel_, (10))\n",
    "mean_corrected = model.mean_restoration(mean)\n",
    "displacement = F.interpolate(mean_corrected - mean, (80),mode='linear')\n",
    "mel_ += displacement\n",
    "mel_ = mel_.transpose(-1,-2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "steps = 100\n",
    "coeff=0.3\n",
    "noise = torch.randn_like(mel_)\n",
    "lat = mel_*coeff+noise*(1-coeff)\n",
    "real = x[start:start+window]\n",
    "\"\"\"\n",
    "def ode_func(t, x):\n",
    "\n",
    "    t_batch = torch.ones(x.shape[0], 1).to(x.device) * t  \n",
    "    flow = model.flow(x, t_batch)\n",
    "    print(flow.std(),flow.mean())\n",
    "    return flow\n",
    "\n",
    "t_span = torch.linspace(coeff, 1, steps)\n",
    "with torch.no_grad():\n",
    "    trajectories = odeint(\n",
    "        ode_func, \n",
    "        lat.detach(), \n",
    "        t_span, \n",
    "        method='euler', \n",
    "        options={'step_size': 1/(steps)} \n",
    "    )\n",
    "    out = trajectories[-1][...,rf:]\n",
    "\"\"\"\n",
    "#flow_ = model.flow(lat,torch.tensor([0]).cuda()) #flow = raw_mels-noise\n",
    "model.flow.last_h=None\n",
    "out = (model.flow(lat,torch.tensor([coeff]).cuda())+noise)[...,rf:]\n",
    "#\"\"\"\n",
    "waveform = model.vocoder(model.mel_denormalize(out)).flatten().cpu().detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0ee54-cf0f-4033-bddf-883da23b2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow( F.interpolate(displacement.clip(min=0), (80),mode='linear').flip(1).cpu().detach().numpy()[0].T[...,rf:],cmap='viridis')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603607e3-d07e-4c28-b3e3-b87b1d08b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(lat[...,rf:].flip(1).cpu().detach().numpy()[0],cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf34407-8632-4ccd-a58c-3dbaf4dcf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(lat[...,rf:].flip(1).cpu().detach().numpy()[0],cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39482f5-4b23-4d3a-97d9-c8f523a7dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "sd.play(waveform[rf*256:],sr)\n",
    "plt.matshow(out.flip(1).cpu().detach().numpy()[0],cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449807d5-6116-4464-9014-9237d2e5debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow((out-lat[...,rf:]).flip(1).cpu().detach().numpy()[0],cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aff745-ca21-40c7-b6af-a22f75300bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "sd.play(real,sr)\n",
    "plt.matshow(mel_[...,rf:].flip(1).cpu().detach().numpy()[0],cmap='viridis')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e3d3f-34bc-49ca-9b5a-ceea2594d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = model.vocoder(model.mel_denormalize(mel_).cuda()).squeeze(0).squeeze(0).cpu().detach().numpy()\n",
    "sd.play(naive,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71c1c0-39f6-46ad-a080-96b362de533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = { \n",
    "    'epoch': i,\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "    'lr_sched': scheduler}\n",
    "torch.save(checkpoint, f'checkpoint_unet{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fc515-863f-4501-813f-b554ecff37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edd536-92f0-46b9-86dd-edfbd0b1abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start,window=1800000,32768*5\n",
    "mel_ = mel_y[start//256:(start+window)//256]\n",
    "plt.matshow(mel_.flip(1).numpy().T,cmap='viridis')\n",
    "plt.plot()\n",
    "true = model.vocoder(mel_.cuda().unsqueeze(0).transpose(-1,-2)).squeeze(0).squeeze(0)\n",
    "sd.play(true.cpu().detach().numpy(),sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a79c5-6035-4ee2-a199-958ba16ec955",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(y[start:(start+window)],sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3609bc9-b45e-4f54-aedc-2ee113153f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltemp = torch.load('test7_unet',weights_only=False).cuda()\n",
    "modeltemp.eval()\n",
    "modeltemp.vocoder.turn_on_caching()\n",
    "modeltemp.flow.turn_on_caching()\n",
    "modeltemp.flow.last_h=None\n",
    "fake2 = torch.tensor([],device='cuda')\n",
    "fake2_mel= torch.tensor([],device='cuda').reshape(1,80,0)\n",
    "with torch.no_grad():\n",
    "    for chunk in mel_orig[0]:\n",
    "        normalized = modeltemp.mel_normalize(chunk.cuda().unsqueeze(0).unsqueeze(2))\n",
    "        noise = torch.randn_like(normalized)\n",
    "        coeff=0.3\n",
    "        lat = noise*(1-coeff)+coeff*normalized\n",
    "        flow = modeltemp.flow(lat,torch.tensor([coeff]).cuda())\n",
    "        out = flow+noise\n",
    "        mel_guitar = modeltemp.mel_denormalize(out)\n",
    "        print(mel_guitar.shape)\n",
    "        fake2_mel = torch.cat((fake2_mel,mel_guitar),dim=-1)\n",
    "        out=modeltemp.vocoder(mel_guitar).flatten()\n",
    "        fake2 = torch.cat((fake2,out),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321da4f4-5482-4228-825f-a05ab77aff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake2=modeltemp.vocoder(fake2_mel).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec8198-1169-483c-8b60-1498b447b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(fake2[rf*256:].cpu().detach().numpy(),sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e9dc2-8313-4219-8892-0da1df5fcc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(waveform[rf*256:],sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e3778a-b498-4f80-9653-44b974a68cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa36f7-010a-47b6-8b82-086d5cec1d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (System)",
   "language": "python",
   "name": "system-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
