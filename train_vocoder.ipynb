{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f49b75b-4c04-44f7-baa4-556d4b08b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GuitarToneCloning\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c305cf3-c096-4b34-83ea-91e0e8db9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GuitarToneCloning().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010f210-37aa-4301-9c2b-18e3908a164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim import AdamW\n",
    "import math\n",
    "\n",
    "class LinearWarmupCosineAnnealingLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, total_steps, decay_factor=0.1, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.decay_factor = decay_factor\n",
    "\n",
    "        self.base_lrs = [group['lr'] for group in optimizer.param_groups]\n",
    "        self.min_lrs = [base_lr * decay_factor for base_lr in self.base_lrs]\n",
    "\n",
    "        super(LinearWarmupCosineAnnealingLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            return [\n",
    "                base_lr * self.last_epoch / self.warmup_steps\n",
    "                for base_lr in self.base_lrs\n",
    "            ]\n",
    "        else:\n",
    "            progress = (self.last_epoch - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
    "            progress = min(max(progress, 0.0), 1.0)\n",
    "            return [\n",
    "                min_lr + (base_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "                for base_lr, min_lr in zip(self.base_lrs, self.min_lrs)\n",
    "            ]\n",
    "\n",
    "no_decay = ['bias', 'norm'] \n",
    "params = list(model.named_parameters())\n",
    "params_generator = list(model.vocoder.named_parameters())\n",
    "params_discriminator = list(model.vocoder_disc.named_parameters())\n",
    "\n",
    "lr = 7e-4\n",
    "loss_weight = {'adv':1,'disc':1,'spec':1,'sn':0.0001}\n",
    "\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "  \n",
    "        'params': [p for n, p in params if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.001,\n",
    "        'lr': lr\n",
    "        },\n",
    "        {\n",
    "        'params': [p for n, p in params if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "        'lr': lr\n",
    "        },\n",
    "]\n",
    "optimizer = AdamW(params=optimizer_grouped_parameters,betas=(0.8,0.99))\n",
    "scheduler = LinearWarmupCosineAnnealingLR(optimizer=optimizer, warmup_steps=2000, total_steps=100000, decay_factor=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c00500-88a6-4e36-9dd3-0f5f4a1fbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import os\n",
    "\n",
    "from itertools import product\n",
    "from utils import yin_pitch_sequence, amplitude_sequence, wave_delta, mel_spectrogram\n",
    "sr=24000\n",
    "y_path=\"violin.wav\"\n",
    "y=torchaudio.load(y_path)\n",
    "y=torchaudio.functional.resample(y[0], y[1], sr)[0]\n",
    "\n",
    "def augment_waveform(waveform, sample_rate, time_stretches, pitch_shifts):\n",
    "\n",
    "    if waveform.dim() == 2 and waveform.size(0) > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "    silence = torch.zeros((int(0.5 * sample_rate)))\n",
    "    results = []\n",
    "\n",
    "    for ts, ps in product(time_stretches, pitch_shifts):\n",
    "        augmented = waveform.clone()\n",
    "        if ts != 1.0:\n",
    "            new_sr = int(sample_rate * ts)\n",
    "            resample = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sr)\n",
    "            augmented = resample(augmented)\n",
    "\n",
    "        if ps != 0:\n",
    "            pitch_shift = torchaudio.transforms.PitchShift(sample_rate=sample_rate, n_steps=ps)\n",
    "            augmented = pitch_shift(augmented)\n",
    "        results.append(augmented.detach())\n",
    "        results.append(silence.detach())\n",
    "    return torch.cat(results[:-1])\n",
    "\n",
    "#\"\"\"\n",
    "import pickle\n",
    "y = augment_waveform(y,sr,[1.1, 1.0, 0.9], [-3,-2,-1,0,1,2,3])\n",
    "with open('cached_augmented_vocoder.pkl','wb') as f:\n",
    "    pickle.dump(y,f)\n",
    "#\"\"\"\n",
    "frame_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7763a496-ad33-4e88-917e-ba8854b482e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cached_augmented_vocoder.pkl','rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f4f18-2236-4ff2-a9a1-6a1e8d5b3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = mel_spectrogram(y.unsqueeze(0)).squeeze(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e079d-bfd6-44d6-878c-2e871aa12d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import copy\n",
    "\n",
    "plt.ion() \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "adv = []\n",
    "disc = []\n",
    "spec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d198b46-a116-4e3b-95c4-afcec3d00b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "N=8\n",
    "model.train()\n",
    "i=0\n",
    "for param in model.vocoder_disc.parameters():\n",
    "    param.requires_grad_(True)\n",
    "while True:\n",
    "    i+=1\n",
    "    training_window = 128\n",
    "    print(f\"{training_window = }\")\n",
    "    y_window = training_window*frame_size\n",
    "    max_x = mel.shape[0]-training_window\n",
    "\n",
    "    \n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    for _ in range(N):\n",
    "        \n",
    "        max_y = y.shape[0]-y_window\n",
    "        x_idx = random.randint(0, max_x)\n",
    "        y_idx = int(x_idx*frame_size)\n",
    "        \n",
    "        x_train = mel[x_idx:x_idx + training_window].T.cuda().unsqueeze(0)\n",
    "        y_train = y[y_idx:y_idx + y_window].cuda().unsqueeze(0)\n",
    "\n",
    "        x_batch.append(x_train)\n",
    "        y_batch.append(y_train)\n",
    "    \n",
    "    x_batch = torch.cat(x_batch, dim=0)\n",
    "    y_batch = torch.cat(y_batch, dim=0).unsqueeze(1)\n",
    "    print(x_batch.shape)\n",
    "    loss_spectral, loss_adv, loss_disc = model.train_vocoder(x_batch,y_batch,optimizer,loss_weight=loss_weight)\n",
    "    scheduler.step()\n",
    "    adv.append(loss_adv)\n",
    "    disc.append(loss_disc)\n",
    "    spec.append(loss_spectral)\n",
    "    if i%10==0:\n",
    "        clear_output(wait=True) \n",
    "        ax.clear()\n",
    "        ax.plot(np.array(adv), label='adv')\n",
    "        ax.plot(np.array(disc), label='disc')\n",
    "        ax.plot(np.array(spec), label='spectral')\n",
    "        ax.legend()\n",
    "        display(fig) \n",
    "        torch.cuda.empty_cache()\n",
    "        if i %1000 == 0 and i!= 0:\n",
    "            torch.save(model,'ckpt'+str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db716fa7-2775-4bd9-907a-5cd4e65769bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = [min(10,value) for value in disc]\n",
    "adv  = [min(10,value) for value in adv]\n",
    "spec = [min(10,value) for value in spec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fc515-863f-4501-813f-b554ecff37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b09e6b-2087-4502-b73a-be8d51ca8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "model.eval()\n",
    "window=364000\n",
    "start=215000000\n",
    "mel_ = mel[start//256:(start+window)//256].unsqueeze(0).transpose(-1,-2).clone()\n",
    "print(mel_.shape)\n",
    "real = y[start:start+window]\n",
    "with torch.no_grad():\n",
    "    fake = model.vocoder(mel_.cuda()).squeeze(0).squeeze(0)\n",
    "print(fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636346a5-4d7b-4def-97d1-59091b636702",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(real.cpu().numpy(),sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a01347-a054-406e-b6a5-62756eb2c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(fake.cpu().detach().numpy(),sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38304089-f35d-444c-8649-01ddfe34f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mel_.cpu().detach().numpy()[0],cmap='grey');plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3609bc9-b45e-4f54-aedc-2ee113153f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder = torch.load('test2',weights_only=False).vocoder.cuda()\n",
    "vocoder.eval()\n",
    "vocoder.turn_on_caching()\n",
    "fake2 = torch.tensor([],device='cuda')\n",
    "with torch.no_grad():\n",
    "    for chunk in mel_[0].T:\n",
    "        #print(chunk.cuda().unsqueeze(0).unsqueeze(2).shape)\n",
    "        out=vocoder(chunk.cuda().unsqueeze(0).unsqueeze(2)).flatten()\n",
    "        fake2 = torch.cat((fake,out),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec8198-1169-483c-8b60-1498b447b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(fake2.cpu().detach().numpy(),sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627d18f-3a02-408f-b6a6-ddb2db4f527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec518187-8c92-4566-a8bc-ded78ba3e7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "System Python2",
   "language": "python",
   "name": "system_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
